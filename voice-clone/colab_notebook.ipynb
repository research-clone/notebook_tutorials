{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vutt-ai-models/notebook_tutorials/blob/main/colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bark text-to-speech voice cloning.\n",
        "Clone voices to create speaker history prompt files (.npz) for [bark text-to-speech](https://github.com/suno-ai/bark).\n",
        "(This version of the notebook is made to work on Google Colab, make sure your runtime hardware accelerator is set to GPU)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "BVBSbNOWoJ9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab: Clone the repository"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1nlUgau-oJ9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bark-voice-cloning-HuBERT-quantizer'...\n",
            "remote: Enumerating objects: 1832, done.\u001b[K\n",
            "remote: Counting objects: 100% (197/197), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 1832 (delta 115), reused 174 (delta 97), pack-reused 1635\u001b[K\n",
            "Receiving objects: 100% (1832/1832), 319.74 MiB | 33.57 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "/content/bark-voice-cloning-HuBERT-quantizer\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer/\n",
        "%cd bark-voice-cloning-HuBERT-quantizer"
      ],
      "metadata": {
        "id": "cp_zB8xioJ9u",
        "outputId": "95a32757-75d4-41d2-f006-3395cf63c7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "collapsed": false,
        "id": "K9UJrXleoJ9v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "70D7agE-oJ9v",
        "outputId": "f8900ad7-4490-41ed-878f-02c852f5c757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Ignoring soundfile: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Collecting audiolm-pytorch (from -r requirements.txt (line 1))\n",
            "  Downloading audiolm_pytorch-1.2.6-py3-none-any.whl (38 kB)\n",
            "Collecting fairseq (from -r requirements.txt (line 2))\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub (from -r requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 4))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from -r requirements.txt (line 5))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from -r requirements.txt (line 6))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sox (from -r requirements.txt (line 8))\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting accelerate (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.1 (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ema-pytorch>=0.2.2 (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 1)) (1.2.0)\n",
            "Collecting lion-pytorch (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Collecting local-attention>=1.8.4 (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading local_attention-1.8.6-py3-none-any.whl (8.1 kB)\n",
            "Collecting scikit-learn==0.24.0 (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading scikit-learn-0.24.0.tar.gz (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 1)) (2.0.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 1)) (4.65.0)\n",
            "Collecting vector-quantize-pytorch>=1.5.14 (from audiolm-pytorch->-r requirements.txt (line 1))\n",
            "  Downloading vector_quantize_pytorch-1.6.23-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.0->audiolm-pytorch->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.0->audiolm-pytorch->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.0->audiolm-pytorch->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 2)) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 2)) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r requirements.txt (line 2))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->-r requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 2)) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->-r requirements.txt (line 2))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->-r requirements.txt (line 2))\n",
            "  Downloading bitarray-2.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 3)) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 5))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r requirements.txt (line 2))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 2))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 2)) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 2)) (4.9.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (16.0.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->audiolm-pytorch->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->-r requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r requirements.txt (line 3)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->audiolm-pytorch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: scikit-learn, fairseq, encodec, antlr4-python3-runtime\n",
            "  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-learn: filename=scikit_learn-0.24.0-cp310-cp310-linux_x86_64.whl size=24891877 sha256=af3ac9ca668cc4df7e2218b062e230a80a0579ceda7dab7c3fc376f478e2eac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/58/c2/13fa991d6624a58064aeaf1b949900a3dcdb4ca046b75f19e8\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11170843 sha256=cca09b949b4fae8177052c8bcd98e686a8b33a5017ccbb55a6d2756134b67ace\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=350bc03ff0f95516e8229ed95e65c7e52e756d07c90b77e4f06980d0730c4363\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2443ab5f04c9116e4490426e9de458365153e9fdc82ed567e59acf02ec312fb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built scikit-learn fairseq encodec antlr4-python3-runtime\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, bitarray, antlr4-python3-runtime, sox, portalocker, omegaconf, einops, colorama, beartype, scikit-learn, sacrebleu, hydra-core, huggingface-hub, transformers, vector-quantize-pytorch, local-attention, lion-pytorch, fairseq, encodec, ema-pytorch, accelerate, audiolm-pytorch\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.10.1 requires scikit-learn>=1.0.2, but you have scikit-learn 0.24.0 which is incompatible.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.20.3 antlr4-python3-runtime-4.8 audiolm-pytorch-1.2.6 beartype-0.14.1 bitarray-2.7.5 colorama-0.4.6 einops-0.6.1 ema-pytorch-0.2.3 encodec-0.1.1 fairseq-0.12.2 huggingface-hub-0.15.1 hydra-core-1.0.7 lion-pytorch-0.1.2 local-attention-1.8.6 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 safetensors-0.3.1 scikit-learn-0.24.0 sentencepiece-0.1.99 sox-1.4.1 tokenizers-0.13.3 transformers-4.30.2 vector-quantize-pytorch-1.6.23\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu117, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models"
      ],
      "metadata": {
        "collapsed": false,
        "id": "UOQzoYyMoJ9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading HuBERT...\n",
            "Downloading HuBERT base model\n",
            "Downloaded HuBERT\n",
            "Loading Quantizer...\n",
            "Downloading HuBERT custom tokenizer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rt_base_ls960_14.pth:   0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f1656b3cfcd43bfb5863dca931854b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded tokenizer\n",
            "Loading Encodec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/encodec/v0/encodec_24khz-d7cc33bc.th\" to /root/.cache/torch/hub/checkpoints/encodec_24khz-d7cc33bc.th\n",
            "100%|██████████| 88.9M/88.9M [00:00<00:00, 105MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and loaded models!\n"
          ]
        }
      ],
      "source": [
        "large_quant_model = False  # Use the larger pretrained model\n",
        "device = 'cuda'  # 'cuda', 'cpu', 'cuda:0', 0, -1, torch.device('cuda')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from encodec import EncodecModel\n",
        "from encodec.utils import convert_audio\n",
        "from hubert.hubert_manager import HuBERTManager\n",
        "from hubert.pre_kmeans_hubert import CustomHubert\n",
        "from hubert.customtokenizer import CustomTokenizer\n",
        "\n",
        "model = ('quantifier_V1_hubert_base_ls960_23.pth', 'tokenizer_large.pth') if large_quant_model else ('quantifier_hubert_base_ls960_14.pth', 'tokenizer.pth')\n",
        "\n",
        "print('Loading HuBERT...')\n",
        "hubert_model = CustomHubert(HuBERTManager.make_sure_hubert_installed(), device=device)\n",
        "print('Loading Quantizer...')\n",
        "quant_model = CustomTokenizer.load_from_checkpoint(HuBERTManager.make_sure_tokenizer_installed(model=model[0], local_file=model[1]), device)\n",
        "print('Loading Encodec...')\n",
        "encodec_model = EncodecModel.encodec_model_24khz()\n",
        "encodec_model.set_target_bandwidth(6.0)\n",
        "encodec_model.to(device)\n",
        "\n",
        "print('Downloaded and loaded models!')"
      ],
      "metadata": {
        "id": "CuWCU7PmoJ9w",
        "outputId": "6470edac-98e1-4327-97c4-e16503917bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "7f1656b3cfcd43bfb5863dca931854b1",
            "ef6d64edaf9a4703a8193e834ed059a9",
            "830b6dd4f0834efbba7c4e736fb7bebd",
            "764ad04838b94897a9e26dcf470b6aad",
            "3376f0cfa97f4555938f8233b2cddd8d",
            "67afb8b0b9f441258f2281549b179d13",
            "50be0a9c7d6640d3b7dbbfc9d4c8b68e",
            "ee8272bb60ef42b8ac98d8f04f31b5c5",
            "486172d152bd4e0a867a440eaa328155",
            "6e140116faa04c4d82493fcda80b14fc",
            "b7c1b1b3e22248c4b5bfa573c0325b8f"
          ]
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load wav and create speaker history prompt"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GGvoK0RVoJ9x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting semantics...\n",
            "Tokenizing semantics...\n",
            "Creating coarse and fine prompts...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "wav_file = 'voicevn.wav'  # Put the path of the speaker you want to use here.\n",
        "out_file = 'speaker.npz'  # Put the path to save the cloned speaker to here.\n",
        "\n",
        "wav, sr = torchaudio.load(wav_file)\n",
        "\n",
        "wav_hubert = wav.to(device)\n",
        "\n",
        "if wav_hubert.shape[0] == 2:  # Stereo to mono if needed\n",
        "    wav_hubert = wav_hubert.mean(0, keepdim=True)\n",
        "\n",
        "print('Extracting semantics...')\n",
        "semantic_vectors = hubert_model.forward(wav_hubert, input_sample_hz=sr)\n",
        "print('Tokenizing semantics...')\n",
        "semantic_tokens = quant_model.get_token(semantic_vectors)\n",
        "print('Creating coarse and fine prompts...')\n",
        "wav = convert_audio(wav, sr, encodec_model.sample_rate, 1).unsqueeze(0)\n",
        "\n",
        "wav = wav.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    encoded_frames = encodec_model.encode(wav)\n",
        "codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()\n",
        "\n",
        "codes = codes.cpu()\n",
        "semantic_tokens = semantic_tokens.cpu()\n",
        "\n",
        "np.savez(out_file,\n",
        "         semantic_prompt=semantic_tokens,\n",
        "         fine_prompt=codes,\n",
        "         coarse_prompt=codes[:2, :]\n",
        "         )\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "26mYzeIeoJ9y",
        "outputId": "cc5a5c46-5a02-4a53-8f80-77e467873fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f1656b3cfcd43bfb5863dca931854b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef6d64edaf9a4703a8193e834ed059a9",
              "IPY_MODEL_830b6dd4f0834efbba7c4e736fb7bebd",
              "IPY_MODEL_764ad04838b94897a9e26dcf470b6aad"
            ],
            "layout": "IPY_MODEL_3376f0cfa97f4555938f8233b2cddd8d"
          }
        },
        "ef6d64edaf9a4703a8193e834ed059a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67afb8b0b9f441258f2281549b179d13",
            "placeholder": "​",
            "style": "IPY_MODEL_50be0a9c7d6640d3b7dbbfc9d4c8b68e",
            "value": "Downloading (…)rt_base_ls960_14.pth: 100%"
          }
        },
        "830b6dd4f0834efbba7c4e736fb7bebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8272bb60ef42b8ac98d8f04f31b5c5",
            "max": 103981977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_486172d152bd4e0a867a440eaa328155",
            "value": 103981977
          }
        },
        "764ad04838b94897a9e26dcf470b6aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e140116faa04c4d82493fcda80b14fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b7c1b1b3e22248c4b5bfa573c0325b8f",
            "value": " 104M/104M [00:00&lt;00:00, 188MB/s]"
          }
        },
        "3376f0cfa97f4555938f8233b2cddd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67afb8b0b9f441258f2281549b179d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50be0a9c7d6640d3b7dbbfc9d4c8b68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8272bb60ef42b8ac98d8f04f31b5c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486172d152bd4e0a867a440eaa328155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e140116faa04c4d82493fcda80b14fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c1b1b3e22248c4b5bfa573c0325b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}