{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vutt-ai-models/transformers_tutorials/blob/main/Intent_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhJHW3SkKnBr",
        "outputId": "6b08ebde-04ea-455f-ec8e-c4a823b2c7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1dYT25oewX-3C4ONpyGcKviv0b-Ah9oJZ/Dungdevunaychim/data/Omer_bert/training-data-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/Shareddrives/NLP Team/Dungdevunaychim/data/Omer_bert/training-data-main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q transformers"
      ],
      "metadata": {
        "id": "Y6GA2_WORW8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "id": "jan3ZivxOlPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Bx1aTqe_Om2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train_intents.json\") as f:\n",
        "  train_data = [json.loads(line) for line in f]\n",
        "with open(\"test_intents.json\") as f:\n",
        "  test_data = [json.loads(line) for line in f]\n",
        "with open(\"valid_intents.json\") as f:\n",
        "  valid_data = [json.loads(line) for line in f]"
      ],
      "metadata": {
        "id": "wENjAGGdOrpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "LR = 1e-5\n",
        "EPOCHS = 10\n",
        "\n",
        "total_data = train_data + test_data + valid_data\n",
        "unique_intentions = set(item['intention'] for item in total_data)\n",
        "NUM_LABEL = len(unique_intentions)"
      ],
      "metadata": {
        "id": "LHiOQsy9QGTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item['text']\n",
        "        label = self.labels[index]\n",
        "        encoded_input = self.tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        input_ids = encoded_input['input_ids'].squeeze()\n",
        "        attention_mask = encoded_input['attention_mask'].squeeze()\n",
        "        return input_ids, attention_mask, label"
      ],
      "metadata": {
        "id": "HaagAFBvP5Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=NUM_LABEL).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZJ8kaPOQOjq",
        "outputId": "adfc66b8-4cf4-4e2f-d2af-070c33891ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get label\n",
        "train_intentions = [item['intention'] for item in train_data]\n",
        "valid_intentions = [item['intention'] for item in valid_data]\n",
        "test_intentions = [item['intention'] for item in test_data]\n",
        "all_intentions = train_intentions + valid_intentions\n",
        "\n",
        "# encode label\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_intentions)\n",
        "train_labels = label_encoder.transform(train_intentions)\n",
        "valid_labels = label_encoder.transform(valid_intentions)\n",
        "test_labels = label_encoder.transform(test_intentions)\n",
        "\n",
        "# define dataloader\n",
        "train_dataset = CustomDataset(train_data, train_labels, tokenizer)\n",
        "valid_dataset = CustomDataset(valid_data, valid_labels, tokenizer)\n",
        "test_dataset = CustomDataset(test_data, test_labels, tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "tlbErafWUoEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "G3G1CD6kU9xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in pbar:\n",
        "        input_ids, attention_mask, label = batch\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits.view(-1, NUM_LABEL), label.view(-1))\n",
        "        pbar.set_description(f\"Updating losss {loss} at epoch {epoch}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS} - Train Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Evaluation on validation data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        for batch in valid_dataloader:\n",
        "            input_ids, attention_mask, label = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "\n",
        "            valid_labels.extend(label.cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "        valid_accuracy = accuracy_score(valid_labels, predicted_labels)\n",
        "        print(f\"Epoch {epoch + 1}/{EPOCHS} - Valid Accuracy: {valid_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "Hx3Q2SudWIfC",
        "outputId": "7f4ca926-7261-4d64-cfb8-c6b31333959d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.8602011799812317 at epoch 0: 100%|██████████| 263/263 [06:35<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Loss: 1.1714\n",
            "Epoch 1/10 - Valid Accuracy: 0.8285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.7097903490066528 at epoch 1: 100%|██████████| 263/263 [06:33<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 - Train Loss: 0.6168\n",
            "Epoch 2/10 - Valid Accuracy: 0.8894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.46397215127944946 at epoch 2: 100%|██████████| 263/263 [06:33<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 - Train Loss: 0.4006\n",
            "Epoch 3/10 - Valid Accuracy: 0.9215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.10035364329814911 at epoch 3: 100%|██████████| 263/263 [06:33<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 - Train Loss: 0.2676\n",
            "Epoch 4/10 - Valid Accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.07214842736721039 at epoch 4: 100%|██████████| 263/263 [06:33<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 - Train Loss: 0.1924\n",
            "Epoch 5/10 - Valid Accuracy: 0.9423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.3033495545387268 at epoch 5: 100%|██████████| 263/263 [06:34<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 - Train Loss: 0.1329\n",
            "Epoch 6/10 - Valid Accuracy: 0.9439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.33996590971946716 at epoch 6: 100%|██████████| 263/263 [06:33<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 - Train Loss: 0.0975\n",
            "Epoch 7/10 - Valid Accuracy: 0.9535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating 0.033895742148160934 at epoch 7:  62%|██████▏   | 164/263 [04:06<02:28,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-90f6d1986bfe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Updating {loss} at epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, attention_mask, label = batch\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        _, predicted = torch.max(logits, dim=1)\n",
        "\n",
        "        test_labels.extend(label.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPrOXZEZW_LD",
        "outputId": "b0331d2a-d30d-4345-f36a-707a5822936b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = [item[\"text\"] for item in test_data[10:20]]\n",
        "true_intent = [item[\"intention\"] for item in test_data[10:20]]\n",
        "test_text, true_intent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HCiV6gyqPrK",
        "outputId": "089797e5-156f-43ac-c341-216fd7a95100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['wanna speak to a customer service',\n",
              "  'two-thousand one-hundred sixty seven three-thousand six-hundred seventy four six-hundred twenty six-hundred two',\n",
              "  'date of transaction 30th november 2021',\n",
              "  'five-hundred seven',\n",
              "  'one-hundred ninety three five-thousand six-hundred nineteen',\n",
              "  'seven-hundred seventy two',\n",
              "  'to put a credit card on my account',\n",
              "  'hi good evening',\n",
              "  's m s',\n",
              "  'for my reward'],\n",
              " ['agent',\n",
              "  'no_intention',\n",
              "  'no_intention',\n",
              "  'no_intention',\n",
              "  'no_intention',\n",
              "  'no_intention',\n",
              "  'register',\n",
              "  'greetings',\n",
              "  'no_intention',\n",
              "  'no_intention'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the texts\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "encoded_inputs = tokenizer(test_text, padding='max_length', truncation=True, return_tensors='pt')\n",
        "\n",
        "input_ids = encoded_inputs['input_ids'].to(device)\n",
        "attention_mask = encoded_inputs['attention_mask'].to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    _, predicted_indices = torch.max(logits, dim=1)\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_indices.cpu().numpy())\n",
        "\n",
        "for text, pred, label in zip(test_text, predicted_labels, true_intent):\n",
        "    print(f\"Text: {text} - Predicted: {pred}, - True label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTxqPit6powm",
        "outputId": "1d078ebf-1100-4a2a-fe9d-478e92303d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: wanna speak to a customer service - Predicted: agent, - True label: agent\n",
            "Text: two-thousand one-hundred sixty seven three-thousand six-hundred seventy four six-hundred twenty six-hundred two - Predicted: no_intention, - True label: no_intention\n",
            "Text: date of transaction 30th november 2021 - Predicted: no_intention, - True label: no_intention\n",
            "Text: five-hundred seven - Predicted: no_intention, - True label: no_intention\n",
            "Text: one-hundred ninety three five-thousand six-hundred nineteen - Predicted: no_intention, - True label: no_intention\n",
            "Text: seven-hundred seventy two - Predicted: no_intention, - True label: no_intention\n",
            "Text: to put a credit card on my account - Predicted: purchase, - True label: register\n",
            "Text: hi good evening - Predicted: greetings, - True label: greetings\n",
            "Text: s m s - Predicted: no_intention, - True label: no_intention\n",
            "Text: for my reward - Predicted: no_intention, - True label: no_intention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VWqu2dCqu68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}